{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b79a2eb8",
   "metadata": {},
   "source": [
    "**Note:** All the codes below are run in Saturn notebook. Therefore huge dataset of images are not in github repo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8135be",
   "metadata": {},
   "source": [
    "**1. check quickly that tensorflow is there in Saturn CLoud**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9baba9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 19:00:14.474335: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29f3966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478806ab",
   "metadata": {},
   "source": [
    "## Homework 08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b931eb8",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we'll build a model for predicting if we have an image of a dino or a dragon. For this, we will use the \"Dino or Dragon?\" dataset that can be downloaded from Kaggle.\n",
    "\n",
    "You can get a wget-able version here:\n",
    "\n",
    "`wget https://github.com/alexeygrigorev/dino-or-dragon/releases/download/data/dino-dragon.zip`\n",
    "\n",
    "`unzip dino-dragon.zip`\n",
    "\n",
    "In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch.\n",
    "\n",
    "**Note:** You will need an environment with a GPU for this homework. We recommend to use [Saturn Cloud](https://bit.ly/saturn-mlzoomcamp). You can also use a computer without a GPU (e.g. your laptop), but it will be slower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38739ff8",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "The dataset contains around 1900 images of dinos and around 1900 images of dragons.\n",
    "\n",
    "The dataset contains separate folders for training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b227f9",
   "metadata": {},
   "source": [
    "## 2. Getting the images for homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7529fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment below if data is not downloaded yet\n",
    "#!wget https://github.com/alexeygrigorev/dino-or-dragon/releases/download/data/dino-dragon.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3f060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below line if data is not unzipped yet\n",
    "#!unzip dino-dragon.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb908d4",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "\n",
    "* The shape for input should be `(150, 150, 3)`\n",
    "* Next, create a convolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "    * Use 32 filters\n",
    "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
    "    * Use `'relu'` as activation \n",
    "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
    "    * Set the pooling size to `(2, 2)`\n",
    "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
    "* Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
    "* Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
    "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
    "\n",
    "* `SGD(lr=0.002, momentum=0.8)`\n",
    "\n",
    "For clarification about kernel size and max pooling, check [Office Hours](https://www.youtube.com/watch?v=1WRgdBTUaAc).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41a825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb19598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11835f17",
   "metadata": {},
   "source": [
    "## Developing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edb39997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 19:01:37.278799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 19:01:37.285212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 19:01:37.285843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 19:01:37.286960: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-23 19:01:37.287336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 19:01:37.287998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 19:01:37.288584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 19:01:37.947334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 19:01:37.948114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 19:01:37.948685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 19:01:37.949208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13795 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "#https://www.tensorflow.org/guide/keras/save_and_serialize\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\\\n",
    "             optimizer=optimizers.SGD(learning_rate=0.002, momentum=0.8),\\\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c4091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa73c15",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "- `binary crossentropy`\n",
    "- `focal loss`\n",
    "- `mean squared error`\n",
    "- `categorical crossentropy`\n",
    "\n",
    "Note: since we specify an activation for the output layer, we don't need to set `from_logits=True`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38507cd3",
   "metadata": {},
   "source": [
    "**Answer to question 1**\n",
    "\n",
    "`binray crossentropy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6754599",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the total number of parameters of the model? You can use the `summary` method for that. \n",
    "\n",
    "- 9215873\n",
    "- 11215873\n",
    "- 14215873\n",
    "- 19215873"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b8002",
   "metadata": {},
   "source": [
    "**Answer to question 2**\n",
    "\n",
    "`11215873`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d69ae2",
   "metadata": {},
   "source": [
    "### Generators and Training\n",
    "\n",
    "For the next two questions, use the following data generator for both train and test sets:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "* We don't need to do any additional pre-processing for the images.\n",
    "* When reading the data from train/test directories, check the `class_mode` parameter. Which value should it be for a binary classification problem?\n",
    "* Use `batch_size=20`\n",
    "* Use `shuffle=True` for both training and test sets. \n",
    "\n",
    "For training use `.fit()` with the following params:\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f7acac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a44c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f56ca99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dino-dragon.zip                       README.md                    \u001b[0m\u001b[01;34mtest\u001b[0m/\r\n",
      "hw08-mlzoomcamp-dino-or-dragon.ipynb  single-gpu-tensorflow.ipynb  \u001b[01;34mtrain\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e9117b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train'\n",
    "test_dir = './test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19581f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_gen.flow_from_directory(train_dir,\n",
    "                                        target_size=(150, 150),\n",
    "                                        batch_size=20,\n",
    "                                        class_mode='binary',\n",
    "                                        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34009c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = test_gen.flow_from_directory(test_dir,\n",
    "                                       target_size=(150, 150),\n",
    "                                       batch_size=20,\n",
    "                                       class_mode='binary',\n",
    "                                       shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2126421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 19:02:56.738625: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-11-23 19:02:57.361335: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-23 19:02:57.362267: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-23 19:02:57.362306: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-23 19:02:57.363335: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-23 19:02:57.363428: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 12s 122ms/step - loss: 0.6937 - acc: 0.5358 - val_loss: 0.6790 - val_acc: 0.4975\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.6495 - acc: 0.6587 - val_loss: 0.6297 - val_acc: 0.5711\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.5588 - acc: 0.7547 - val_loss: 0.5032 - val_acc: 0.8020\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.4654 - acc: 0.7936 - val_loss: 0.4115 - val_acc: 0.8477\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.4154 - acc: 0.8231 - val_loss: 0.3802 - val_acc: 0.8579\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.3597 - acc: 0.8513 - val_loss: 0.3403 - val_acc: 0.8528\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.3218 - acc: 0.8720 - val_loss: 0.3590 - val_acc: 0.8426\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.2951 - acc: 0.8852 - val_loss: 0.3329 - val_acc: 0.8553\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2681 - acc: 0.8908 - val_loss: 0.3368 - val_acc: 0.8579\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2409 - acc: 0.9103 - val_loss: 0.3165 - val_acc: 0.8655\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=test_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61390755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372020125389099"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "acc_median = np.median(acc)\n",
    "acc_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dd3cbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15246697522258218"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "loss_std = np.std(loss)\n",
    "loss_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f47d8a",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "- 0.40\n",
    "- 0.60\n",
    "- 0.90\n",
    "- 0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a607df0",
   "metadata": {},
   "source": [
    "**Answer to question 3**\n",
    "\n",
    "`0.90` (closest answer to 0.86)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a7b96e",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "- 0.11\n",
    "- 0.66\n",
    "- 0.99\n",
    "- 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af057e5",
   "metadata": {},
   "source": [
    "**Answer to question 4**\n",
    "`0.11` (closest answer to my answer 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3ce9e",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations. \n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "* `rotation_range=40,`\n",
    "* `width_shift_range=0.2,`\n",
    "* `height_shift_range=0.2,`\n",
    "* `shear_range=0.2,`\n",
    "* `zoom_range=0.2,`\n",
    "* `horizontal_flip=True,`\n",
    "* `fill_mode='nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c878a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e365da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dea5b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23c328af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150, 150), \n",
    "                                                    batch_size=32, \n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a508038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39c7948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 15s 295ms/step - loss: 0.4631 - acc: 0.7886 - val_loss: 0.3560 - val_acc: 0.8426\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 15s 292ms/step - loss: 0.4458 - acc: 0.7986 - val_loss: 0.2937 - val_acc: 0.8756\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 15s 292ms/step - loss: 0.4576 - acc: 0.7898 - val_loss: 0.3034 - val_acc: 0.8756\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 14s 290ms/step - loss: 0.4213 - acc: 0.8087 - val_loss: 0.3263 - val_acc: 0.8629\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 14s 289ms/step - loss: 0.4234 - acc: 0.8137 - val_loss: 0.3716 - val_acc: 0.8350\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 14s 289ms/step - loss: 0.3995 - acc: 0.8187 - val_loss: 0.2795 - val_acc: 0.8731\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 14s 290ms/step - loss: 0.3923 - acc: 0.8174 - val_loss: 0.3651 - val_acc: 0.8426\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 14s 289ms/step - loss: 0.3825 - acc: 0.8344 - val_loss: 0.4463 - val_acc: 0.8020\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 14s 287ms/step - loss: 0.4102 - acc: 0.8156 - val_loss: 0.6382 - val_acc: 0.7005\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 15s 296ms/step - loss: 0.3891 - acc: 0.8218 - val_loss: 0.3136 - val_acc: 0.8655\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425057a6",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "Make sure you don't re-create the model - we want to continue training the model\n",
    "we already started training.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "- 0.15\n",
    "- 0.77\n",
    "- 0.37\n",
    "- 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d56edc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3693745702505112"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_aug = history.history['val_loss']\n",
    "loss_mean_aug = np.mean(val_loss_aug)\n",
    "loss_mean_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d5fc34",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10)\n",
    "for the model trained with augmentations?\n",
    "\n",
    "- 0.84\n",
    "- 0.54\n",
    "- 0.44\n",
    "- 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbc033b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8167512655258179"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_aug = history.history['val_acc']\n",
    "acc_mean_aug = np.mean(val_acc_aug[5:10])\n",
    "acc_mean_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c730d",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "- Submit your results here: https://forms.gle/XdH5ztBddvTvxzpT6\n",
    "- You can submit your solution multiple times. In this case, only the last submission will be used\n",
    "- If your answer doesn't match options exactly, select the closest one\n",
    "\n",
    "\n",
    "## Deadline\n",
    "\n",
    "The deadline for submitting is 21 November 2022, 23:00 CEST.\n",
    "\n",
    "After that, the form will be closed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
